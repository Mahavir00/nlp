{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Hands_On_3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P78lfzddRPYJ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FkNzmK4RCCk",
        "outputId": "a6b15b58-9170-4031-dd85-1e56ef06bbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from urllib import request\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-wwUvn3RffB"
      },
      "source": [
        "# POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieS2UGcXQqJk",
        "outputId": "2abbb0f5-518c-412a-80da-0032f36d70c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "#  'Leaves Compared With Flowers' by Robert Frost\n",
        "poem = ['''A tree’s leaves may be ever so good,\n",
        "So may its bark, so may its wood;\n",
        "But unless you put the right thing to its root\n",
        "It never will show much flower or fruit.''',\n",
        "'''But I may be one who does not care\n",
        "Ever to have tree bloom or bear.\n",
        "Leaves for smooth and bark for rough,\n",
        "Leaves and bark may be tree enough.''',\n",
        "'''Some giant trees have bloom so small\n",
        "They might as well have none at all.\n",
        "Late in life I have come on fern.\n",
        "Now lichens are due to have their turn.''',\n",
        "'''I bade men tell me which in brief,\n",
        "Which is fairer, flower or leaf.\n",
        "They did not have the wit to say,\n",
        "Leaves by night and flowers by day.''',\n",
        "'''Leaves and bark, leaves and bark,\n",
        "To lean against and hear in the dark.\n",
        "Petals I may have once pursued.\n",
        "Leaves are all my darker mood.''']\n",
        "\n",
        "pos_tags = []\n",
        "for verse in poem:\n",
        "    sentences = nltk.sent_tokenize(verse)\n",
        "    for sentence in sentences:\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        pos_tags.append(nltk.pos_tag(words))\n",
        "for i in pos_tags:\n",
        "  print(i)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('A', 'DT'), ('tree', 'JJ'), ('’', 'NN'), ('s', 'NN'), ('leaves', 'VBZ'), ('may', 'MD'), ('be', 'VB'), ('ever', 'RB'), ('so', 'RB'), ('good', 'JJ'), (',', ','), ('So', 'NNP'), ('may', 'MD'), ('its', 'PRP$'), ('bark', 'NN'), (',', ','), ('so', 'RB'), ('may', 'MD'), ('its', 'PRP$'), ('wood', 'NN'), (';', ':'), ('But', 'CC'), ('unless', 'IN'), ('you', 'PRP'), ('put', 'VBP'), ('the', 'DT'), ('right', 'JJ'), ('thing', 'NN'), ('to', 'TO'), ('its', 'PRP$'), ('root', 'NN'), ('It', 'PRP'), ('never', 'RB'), ('will', 'MD'), ('show', 'VB'), ('much', 'JJ'), ('flower', 'JJR'), ('or', 'CC'), ('fruit', 'NN'), ('.', '.')]\n",
            "[('But', 'CC'), ('I', 'PRP'), ('may', 'MD'), ('be', 'VB'), ('one', 'CD'), ('who', 'WP'), ('does', 'VBZ'), ('not', 'RB'), ('care', 'VB'), ('Ever', 'RB'), ('to', 'TO'), ('have', 'VB'), ('tree', 'JJ'), ('bloom', 'NN'), ('or', 'CC'), ('bear', 'NN'), ('.', '.')]\n",
            "[('Leaves', 'NNS'), ('for', 'IN'), ('smooth', 'NN'), ('and', 'CC'), ('bark', 'NN'), ('for', 'IN'), ('rough', 'NN'), (',', ','), ('Leaves', 'NNP'), ('and', 'CC'), ('bark', 'NN'), ('may', 'MD'), ('be', 'VB'), ('tree', 'JJ'), ('enough', 'RB'), ('.', '.')]\n",
            "[('Some', 'DT'), ('giant', 'JJ'), ('trees', 'NNS'), ('have', 'VBP'), ('bloom', 'VBN'), ('so', 'RB'), ('small', 'JJ'), ('They', 'PRP'), ('might', 'MD'), ('as', 'RB'), ('well', 'RB'), ('have', 'VB'), ('none', 'NN'), ('at', 'IN'), ('all', 'DT'), ('.', '.')]\n",
            "[('Late', 'RB'), ('in', 'IN'), ('life', 'NN'), ('I', 'PRP'), ('have', 'VBP'), ('come', 'VBN'), ('on', 'IN'), ('fern', 'NN'), ('.', '.')]\n",
            "[('Now', 'RB'), ('lichens', 'VBZ'), ('are', 'VBP'), ('due', 'JJ'), ('to', 'TO'), ('have', 'VB'), ('their', 'PRP$'), ('turn', 'NN'), ('.', '.')]\n",
            "[('I', 'PRP'), ('bade', 'VBP'), ('men', 'NNS'), ('tell', 'VB'), ('me', 'PRP'), ('which', 'WDT'), ('in', 'IN'), ('brief', 'NN'), (',', ','), ('Which', 'NNP'), ('is', 'VBZ'), ('fairer', 'JJR'), (',', ','), ('flower', 'JJR'), ('or', 'CC'), ('leaf', 'NN'), ('.', '.')]\n",
            "[('They', 'PRP'), ('did', 'VBD'), ('not', 'RB'), ('have', 'VB'), ('the', 'DT'), ('wit', 'NN'), ('to', 'TO'), ('say', 'VB'), (',', ','), ('Leaves', 'NNS'), ('by', 'IN'), ('night', 'NN'), ('and', 'CC'), ('flowers', 'NNS'), ('by', 'IN'), ('day', 'NN'), ('.', '.')]\n",
            "[('Leaves', 'NNS'), ('and', 'CC'), ('bark', 'NN'), (',', ','), ('leaves', 'NNS'), ('and', 'CC'), ('bark', 'NN'), (',', ','), ('To', 'TO'), ('lean', 'VB'), ('against', 'IN'), ('and', 'CC'), ('hear', 'VB'), ('in', 'IN'), ('the', 'DT'), ('dark', 'NN'), ('.', '.')]\n",
            "[('Petals', 'NNS'), ('I', 'PRP'), ('may', 'MD'), ('have', 'VB'), ('once', 'RB'), ('pursued', 'VBN'), ('.', '.')]\n",
            "[('Leaves', 'NNS'), ('are', 'VBP'), ('all', 'DT'), ('my', 'PRP$'), ('darker', 'NN'), ('mood', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jw6x11OQqJv"
      },
      "source": [
        "# Scrapping Web Data and Tweet Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp3JCU0kQqJs",
        "outputId": "9bc92cd8-d262-49d9-9fd6-3b8960826c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text = '''\"We are going to go to the moon, we are going to have a base on the moon, we are going to send people to mars and make life multi-planetary. This day heralds a new age of space exploration\" — @elonmusk'''\n",
        "tt = TweetTokenizer()\n",
        "print(tt.tokenize(text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\"', 'We', 'are', 'going', 'to', 'go', 'to', 'the', 'moon', ',', 'we', 'are', 'going', 'to', 'have', 'a', 'base', 'on', 'the', 'moon', ',', 'we', 'are', 'going', 'to', 'send', 'people', 'to', 'mars', 'and', 'make', 'life', 'multi-planetary', '.', 'This', 'day', 'heralds', 'a', 'new', 'age', 'of', 'space', 'exploration', '\"', '—', '@elonmusk']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9l_9vB9QqJw",
        "outputId": "bc0aa374-3a5a-4768-e7bb-b3c0a0d49858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf8')\n",
        "tokens = word_tokenize(raw)\n",
        "\n",
        "type(raw),len(raw),raw[:75],type(tokens)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(str,\n",
              " 1176967,\n",
              " '\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r',\n",
              " list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnYjpJn8UQHn"
      },
      "source": [
        "<h2> HTML - ASCII - TEXT - VOCAB </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35AkRlMFQqJ5",
        "outputId": "db535566-1e57-4ed4-8a24-a4477b3aa559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#HANDLING TWEETS\n",
        "text = '''\"We are going to go to the moon, we are going to have a base on the moon, we are going to send people to mars and make life multi-planetary. This day heralds a new age of space exploration\" — @elonmusk'''\n",
        "nltk_text = nltk.Text(text.split())\n",
        "nltk_text.concordance(\"base\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying 1 of 1 matches:\n",
            "                                     base on the moon, we are going to send pe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MYwfaQoQqJ7",
        "outputId": "c073ec19-8ad4-4cea-8828-fe09534f7c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(text), type(nltk_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(str, nltk.text.Text)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}